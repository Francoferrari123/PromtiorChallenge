services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    entrypoint: [ "/bin/bash", "-c", "ollama serve & sleep 5 && ollama pull mistral && wait" ]
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    networks:
      - promtior-network

  redis:
    image: redis:7-alpine
    container_name: redis
    restart: unless-stopped
    networks:
      - promtior-network
    volumes:
      - redis_data:/data
    command: [ "redis-server", "--appendonly", "yes" ]

  api:
    image: ghcr.io/francoferrari123/promtior-backend:latest
    container_name: promtior-api
    depends_on:
      - ollama
      - redis
    volumes:
      - ./data/faiss_index:/app/faiss_index
      - ./data/RAG_data:/app/RAG_data
    restart: unless-stopped
    networks:
      - promtior-network
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      OLLAMA_BASE_URL: http://ollama:11434
      REDIS_URL: redis://redis:6379
      VECTORSTORE_PATH: /app/faiss_index
      PDF_PATH: /app/RAG_data/promtior.pdf

  frontend:
    image: ghcr.io/francoferrari123/promtior-frontend:latest
    container_name: promtior-frontend
    depends_on:
      - api
    restart: unless-stopped
    networks:
      - promtior-network

  nginx:
    image: nginx:alpine
    container_name: promtior-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - frontend
      - api
    restart: unless-stopped
    networks:
      - promtior-network

volumes:
  ollama_data:
  redis_data:


networks:
  promtior-network:
    driver: bridge
